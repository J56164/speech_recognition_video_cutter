{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (from moviepy) (5.1.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (from moviepy) (2.36.1)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (from moviepy) (2.0.2)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (from moviepy) (1.0.1)\n",
      "Requirement already satisfied: pillow<11.0,>=9.2.0 in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (from moviepy) (10.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (from proglog<=1.0.0->moviepy) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jj\\documents\\files\\jj_work\\personalprogrammingprojects\\python\\speech_recognition_video_cutter\\env\\lib\\site-packages (from tqdm->proglog<=1.0.0->moviepy) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VideoCutter import VideoCutter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = Path(\"..\")\n",
    "RECORDINGS_PATH = PROJECT_PATH / \"recordings\"\n",
    "RECORDING_FILE_PATH = RECORDINGS_PATH / \"Recording.m4a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import VideoFileClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_FILE_PATH = RECORDINGS_PATH / \"video.mp4\"\n",
    "VIDEO_OUTPUT_FILE_PATH = RECORDINGS_PATH / \"clip.mp4\"\n",
    "AUDIO_OUTPUT_FILE_PATH = RECORDINGS_PATH / \"audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recognize audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': ' Today I want to talk about the specific space recognition video pattern, which is a practice',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 9.84,\n",
       "   'text': ' Today I want to talk about the specific space recognition video pattern, which is a practice',\n",
       "   'tokens': [50363,\n",
       "    6288,\n",
       "    314,\n",
       "    765,\n",
       "    284,\n",
       "    1561,\n",
       "    546,\n",
       "    262,\n",
       "    2176,\n",
       "    2272,\n",
       "    9465,\n",
       "    2008,\n",
       "    3912,\n",
       "    11,\n",
       "    543,\n",
       "    318,\n",
       "    257,\n",
       "    3357,\n",
       "    50855],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.9292236509777251,\n",
       "   'compression_ratio': 1.1219512195121952,\n",
       "   'no_speech_prob': 0.28270867466926575}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VideoCutter().recognize_audio(RECORDING_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cut video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video ../recordings/0.mp4.\n",
      "MoviePy - Writing audio in 0TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../recordings/0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../recordings/0.mp4\n",
      "MoviePy - Building video ../recordings/1.mp4.\n",
      "MoviePy - Writing audio in 1TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../recordings/1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../recordings/1.mp4\n",
      "MoviePy - Building video ../recordings/2.mp4.\n",
      "MoviePy - Writing audio in 2TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../recordings/2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../recordings/2.mp4\n",
      "MoviePy - Building video ../recordings/3.mp4.\n",
      "MoviePy - Writing audio in 3TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../recordings/3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../recordings/3.mp4\n"
     ]
    }
   ],
   "source": [
    "cut_timestamps = [1, 3, 7]\n",
    "VideoCutter().cut_video(VIDEO_FILE_PATH, cut_timestamps, RECORDINGS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Temp file test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JJ\\AppData\\Local\\Temp\\tmp889i5q0l.mp4\n",
      "MoviePy - Building video C:/Users/JJ/AppData/Local/Temp/tmp889i5q0l.mp4.\n",
      "MoviePy - Writing audio in tmp889i5q0lTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video C:/Users/JJ/AppData/Local/Temp/tmp889i5q0l.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame_index:   7%|▋         | 9280/127932 [02:18<23:03, 85.74it/s, now=None]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     temp_filepath \u001b[38;5;241m=\u001b[39m Path(file\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(temp_filepath)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_videofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_filepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_posix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Delete file\u001b[39;00m\n\u001b[0;32m      9\u001b[0m temp_filepath\u001b[38;5;241m.\u001b[39munlink()\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\decorators.py:53\u001b[0m, in \u001b[0;36mrequires_duration\u001b[1;34m(func, clip, *args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(clip, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\decorators.py:143\u001b[0m, in \u001b[0;36muse_clip_fps_by_default\u001b[1;34m(func, clip, *args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m new_args \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    136\u001b[0m     find_fps(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, names)\n\u001b[0;32m    137\u001b[0m ]\n\u001b[0;32m    138\u001b[0m new_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    139\u001b[0m     kwarg: find_fps(value) \u001b[38;5;28;01mif\u001b[39;00m kwarg \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfps\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (kwarg, value) \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    141\u001b[0m }\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(clip, \u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\decorators.py:24\u001b[0m, in \u001b[0;36mconvert_masks_to_RGB\u001b[1;34m(func, clip, *args, **kwargs)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mis_mask:\n\u001b[0;32m     23\u001b[0m     clip \u001b[38;5;241m=\u001b[39m clip\u001b[38;5;241m.\u001b[39mto_RGB()\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(clip, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\decorators.py:94\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m new_args \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m     fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;129;01min\u001b[39;00m varnames) \u001b[38;5;129;01mand\u001b[39;00m (arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, names)\n\u001b[0;32m     89\u001b[0m ]\n\u001b[0;32m     90\u001b[0m new_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     91\u001b[0m     kwarg: fun(value) \u001b[38;5;28;01mif\u001b[39;00m kwarg \u001b[38;5;129;01min\u001b[39;00m varnames \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (kwarg, value) \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     93\u001b[0m }\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\video\\VideoClip.py:391\u001b[0m, in \u001b[0;36mVideoClip.write_videofile\u001b[1;34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, temp_audiofile_path, remove_temp, write_logfile, threads, ffmpeg_params, logger, pixel_format)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m make_audio:\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mwrite_audiofile(\n\u001b[0;32m    381\u001b[0m         audiofile,\n\u001b[0;32m    382\u001b[0m         audio_fps,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m         logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[0;32m    389\u001b[0m     )\n\u001b[1;32m--> 391\u001b[0m \u001b[43mffmpeg_write_video\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbitrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbitrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_logfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_logfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudiofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudiofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mffmpeg_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mffmpeg_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remove_temp \u001b[38;5;129;01mand\u001b[39;00m make_audio:\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(audiofile):\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_writer.py:256\u001b[0m, in \u001b[0;36mffmpeg_write_video\u001b[1;34m(clip, filename, fps, codec, bitrate, preset, write_logfile, audiofile, threads, ffmpeg_params, logger, pixel_format)\u001b[0m\n\u001b[0;32m    242\u001b[0m     pixel_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgba\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb24\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m FFMPEG_VideoWriter(\n\u001b[0;32m    244\u001b[0m     filename,\n\u001b[0;32m    245\u001b[0m     clip\u001b[38;5;241m.\u001b[39msize,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m     pixel_format\u001b[38;5;241m=\u001b[39mpixel_format,\n\u001b[0;32m    255\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t, frame \u001b[38;5;129;01min\u001b[39;00m clip\u001b[38;5;241m.\u001b[39miter_frames(\n\u001b[0;32m    257\u001b[0m         logger\u001b[38;5;241m=\u001b[39mlogger, with_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fps\u001b[38;5;241m=\u001b[39mfps, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m     ):\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m clip\u001b[38;5;241m.\u001b[39mmask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    260\u001b[0m             mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m clip\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mget_frame(t)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\Clip.py:535\u001b[0m, in \u001b[0;36mClip.iter_frames\u001b[1;34m(self, fps, with_times, logger, dtype)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_index \u001b[38;5;129;01min\u001b[39;00m logger\u001b[38;5;241m.\u001b[39miter_bar(\n\u001b[0;32m    529\u001b[0m     frame_index\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduration \u001b[38;5;241m*\u001b[39m fps))\n\u001b[0;32m    530\u001b[0m ):\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;66;03m# int is used to ensure that floating point errors are rounded\u001b[39;00m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# down to the nearest integer\u001b[39;00m\n\u001b[0;32m    533\u001b[0m     t \u001b[38;5;241m=\u001b[39m frame_index \u001b[38;5;241m/\u001b[39m fps\n\u001b[1;32m--> 535\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (frame\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype):\n\u001b[0;32m    537\u001b[0m         frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mastype(dtype)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\decorators.py:94\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m new_args \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m     fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name \u001b[38;5;129;01min\u001b[39;00m varnames) \u001b[38;5;129;01mand\u001b[39;00m (arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, names)\n\u001b[0;32m     89\u001b[0m ]\n\u001b[0;32m     90\u001b[0m new_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     91\u001b[0m     kwarg: fun(value) \u001b[38;5;28;01mif\u001b[39;00m kwarg \u001b[38;5;129;01min\u001b[39;00m varnames \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (kwarg, value) \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m     93\u001b[0m }\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39mnew_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\Clip.py:87\u001b[0m, in \u001b[0;36mClip.get_frame\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m frame\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\video\\io\\VideoFileClip.py:139\u001b[0m, in \u001b[0;36mVideoFileClip.__init__.<locals>.<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask\u001b[38;5;241m.\u001b[39mfps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfps\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Make a reader for the audio, if any.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39minfos[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_found\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:228\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.get_frame\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# If pos == self.pos + 1, this line has no effect\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_frames(pos \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 228\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\moviepy\\video\\io\\ffmpeg_reader.py:154\u001b[0m, in \u001b[0;36mFFMPEG_VideoReader.read_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    151\u001b[0m w, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m    152\u001b[0m nbytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m*\u001b[39m w \u001b[38;5;241m*\u001b[39m h\n\u001b[1;32m--> 154\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s) \u001b[38;5;241m!=\u001b[39m nbytes:\n\u001b[0;32m    157\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    158\u001b[0m         (\n\u001b[0;32m    159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m bytes wanted but \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m bytes read at frame index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    173\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video = VideoFileClip(VIDEO_FILE_PATH.as_posix())\n",
    "with tempfile.NamedTemporaryFile(\"wb\", suffix=\".mp4\", delete=False) as file:\n",
    "    temp_filepath = Path(file.name)\n",
    "    print(temp_filepath)\n",
    "\n",
    "video.write_videofile(temp_filepath.as_posix())\n",
    "\n",
    "# Delete file\n",
    "temp_filepath.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6297/6297 [00:05<00:00, 1205.59frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "7.0\n",
      " Okay, one two two is that. Okay, so today I'm going to show you.\n",
      "None\n",
      "7.0\n",
      "9.0\n",
      " I need this.\n",
      "None\n",
      "9.0\n",
      "11.0\n",
      " Cut cut.\n",
      "<re.Match object; span=(1, 4), match='Cut'>\n",
      "11.0\n",
      "13.0\n",
      " Okay, so.\n",
      "None\n",
      "13.0\n",
      "16.0\n",
      " And I saw you.\n",
      "None\n",
      "16.0\n",
      "20.0\n",
      " The, the second mission will cut that with.\n",
      "<re.Match object; span=(30, 33), match='cut'>\n",
      "20.0\n",
      "24.0\n",
      " I've been, I've been making for.\n",
      "None\n",
      "24.0\n",
      "26.0\n",
      " Cut.\n",
      "<re.Match object; span=(1, 4), match='Cut'>\n",
      "27.0\n",
      "30.0\n",
      " I've been making for.\n",
      "None\n",
      "30.0\n",
      "33.0\n",
      " Like five, five months, a cutting cut.\n",
      "<re.Match object; span=(35, 38), match='cut'>\n",
      "33.0\n",
      "37.0\n",
      " Wish I'd be making for five days.\n",
      "None\n",
      "37.0\n",
      "39.0\n",
      " Also.\n",
      "None\n",
      "39.0\n",
      "41.0\n",
      " Um, six.\n",
      "None\n",
      "41.0\n",
      "43.0\n",
      " Uh, in fact.\n",
      "None\n",
      "43.0\n",
      "45.0\n",
      " Okay, so.\n",
      "None\n",
      "45.0\n",
      "47.0\n",
      " Listing will catch.\n",
      "None\n",
      "47.0\n",
      "49.0\n",
      " We'll be all given.\n",
      "None\n",
      "49.0\n",
      "55.0\n",
      " Whenever the video said cut.\n",
      "<re.Match object; span=(25, 28), match='cut'>\n",
      "56.0\n",
      "61.0\n",
      " Okay, so I'm going to take it now and.\n",
      "None\n",
      "61.0\n",
      "65.0\n",
      " Okay, so my.\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.0, 20.0, 26.0, 33.0, 55.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognization = VideoCutter().recognize_audio(VIDEO_FILE_PATH)\n",
    "cut_timelines = []\n",
    "for segment in recognization[\"segments\"]:\n",
    "    print(segment[\"start\"])\n",
    "    print(segment[\"end\"])\n",
    "    print(segment[\"text\"])\n",
    "    print(re.search(r\"\\bcut\\b\", segment[\"text\"], re.IGNORECASE))\n",
    "    if re.search(r\"\\bcut\\b\", segment[\"text\"], re.IGNORECASE):\n",
    "        cut_timelines.append(segment[\"end\"])\n",
    "cut_timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JJ\\Documents\\Files\\JJ_work\\PersonalProgrammingProjects\\Python\\speech_recognition_video_cutter\\env\\lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "100%|██████████| 6297/6297 [00:05<00:00, 1180.67frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "7.0\n",
      " Okay, one two two is that. Okay, so today I'm going to show you.\n",
      "None\n",
      "7.0\n",
      "9.0\n",
      " I need this.\n",
      "None\n",
      "9.0\n",
      "11.0\n",
      " Cut cut.\n",
      "<re.Match object; span=(1, 4), match='Cut'>\n",
      "11.0\n",
      "13.0\n",
      " Okay, so.\n",
      "None\n",
      "13.0\n",
      "16.0\n",
      " And I saw you.\n",
      "None\n",
      "16.0\n",
      "20.0\n",
      " The, the second mission will cut that with.\n",
      "<re.Match object; span=(30, 33), match='cut'>\n",
      "20.0\n",
      "24.0\n",
      " I've been, I've been making for.\n",
      "None\n",
      "24.0\n",
      "26.0\n",
      " Cut.\n",
      "<re.Match object; span=(1, 4), match='Cut'>\n",
      "27.0\n",
      "30.0\n",
      " I've been making for.\n",
      "None\n",
      "30.0\n",
      "33.0\n",
      " Like five, five months, a cutting cut.\n",
      "<re.Match object; span=(35, 38), match='cut'>\n",
      "33.0\n",
      "37.0\n",
      " Wish I'd be making for five days.\n",
      "None\n",
      "37.0\n",
      "39.0\n",
      " Also.\n",
      "None\n",
      "39.0\n",
      "41.0\n",
      " Um, six.\n",
      "None\n",
      "41.0\n",
      "43.0\n",
      " Uh, in fact.\n",
      "None\n",
      "43.0\n",
      "45.0\n",
      " Okay, so.\n",
      "None\n",
      "45.0\n",
      "47.0\n",
      " Listing will catch.\n",
      "None\n",
      "47.0\n",
      "49.0\n",
      " We'll be all given.\n",
      "None\n",
      "49.0\n",
      "55.0\n",
      " Whenever the video said cut.\n",
      "<re.Match object; span=(25, 28), match='cut'>\n",
      "56.0\n",
      "61.0\n",
      " Okay, so I'm going to take it now and.\n",
      "None\n",
      "61.0\n",
      "65.0\n",
      " Okay, so my.\n",
      "None\n",
      "MoviePy - Building video ../recordings/0.mp4.\n",
      "MoviePy - Writing audio in 0TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../recordings/0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../recordings/0.mp4\n",
      "MoviePy - Building video ../recordings/1.mp4.\n",
      "MoviePy - Writing audio in 1TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../recordings/1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../recordings/1.mp4\n",
      "MoviePy - Building video ../recordings/2.mp4.\n",
      "MoviePy - Writing audio in 2TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../recordings/2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../recordings/2.mp4\n",
      "MoviePy - Building video ../recordings/3.mp4.\n",
      "MoviePy - Writing audio in 3TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../recordings/3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../recordings/3.mp4\n",
      "MoviePy - Building video ../recordings/4.mp4.\n",
      "MoviePy - Writing audio in 4TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../recordings/4.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../recordings/4.mp4\n",
      "MoviePy - Building video ../recordings/5.mp4.\n",
      "MoviePy - Writing audio in 5TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video ../recordings/5.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ../recordings/5.mp4\n"
     ]
    }
   ],
   "source": [
    "VideoCutter().cut_video_recognize(VIDEO_FILE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
